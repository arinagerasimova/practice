{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK и Python для работы с текстами\n",
    " \n",
    "   Nutural Language Toolkit (NLTK) - это библиотека методов для машинной обработки естественного языка. \n",
    "   С помощью NLTK можно решить такие задачи: вычисление базовой статистики текста,  работа с корпусами и лексикографическими ресурсами, обработка естественного языка (токенизация, лемматизация, стемминг, pos-tagging, parsing), классификация, машинный перевод, работа с XML-документами, представление знаний.\n",
    "\n",
    "   В этот раз мы рассмотрим задачу обработки естественного языка. Для начала работы нужно запустить Python Shell и подключить библиотеку NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала добавим необходимые пакеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Tom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И добавим необходимые библиотеки: word_tokenize (для деления предложения на слова), sent_tokenize (для деления текста на предложения), pos_tag (для опредения слова, как части речи) и FreqDist (для определения частоты слов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize,sent_tokenize, pos_tag, FreqDist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим переменную которой присвоем текст, с которым дальше будем работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"London is the capital of Great Britain. It is one of the greatest cities inthe world. It is an important business and financial centre. It is an intellectual centre, too.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация\n",
    "Токенизация (сегментация) - деление текста на отдельные единицы (предложения, слова). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London is the capital of Great Britain.',\n",
       " 'It is one of the greatest cities inthe world.',\n",
       " 'It is an important business and financial centre.',\n",
       " 'It is an intellectual centre, too.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_text=sent_tokenize(text)\n",
    "sent_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London',\n",
       " 'is',\n",
       " 'the',\n",
       " 'capital',\n",
       " 'of',\n",
       " 'Great',\n",
       " 'Britain',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'cities',\n",
       " 'inthe',\n",
       " 'world',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'an',\n",
       " 'important',\n",
       " 'business',\n",
       " 'and',\n",
       " 'financial',\n",
       " 'centre',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'an',\n",
       " 'intellectual',\n",
       " 'centre',\n",
       " ',',\n",
       " 'too',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_text=word_tokenize(text)\n",
    "word_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нахождение слова в контексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matches\n"
     ]
    }
   ],
   "source": [
    "nltk.Text(word_text).concordance(\"I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 1 of 1 matches:\n",
      " London is the capital of Great Britain . It\n"
     ]
    }
   ],
   "source": [
    "nltk.Text(word_text).concordance(\"London\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация\n",
    "Лемматизация - привидения словоформ к словарной форме (основе)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London',\n",
       " 'is',\n",
       " 'the',\n",
       " 'capital',\n",
       " 'of',\n",
       " 'Great',\n",
       " 'Britain',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'city',\n",
       " 'inthe',\n",
       " 'world',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'an',\n",
       " 'important',\n",
       " 'business',\n",
       " 'and',\n",
       " 'financial',\n",
       " 'centre',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'an',\n",
       " 'intellectual',\n",
       " 'centre',\n",
       " ',',\n",
       " 'too',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl=nltk.stem.WordNetLemmatizer()\n",
    "[wnl.lemmatize(w) for w in word_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-tagging\n",
    " POS tagging (частеречная разметка) - этап автоматической обработки текста, задачей которого является определение части речи и грамматических характеристик слов в тексте (корпусе) с приписыванием им соответствующих тегов. POS tagging является одним из первых этапов компьютерного анализа текста.\n",
    "<img src=\"https://csdl-images.computer.org/mags/mu/2007/01/figures/u1083t1.gif\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала определим какой частью речи является каждое слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('London', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('capital', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Great', 'NNP'),\n",
       " ('Britain', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('greatest', 'JJS'),\n",
       " ('cities', 'NNS'),\n",
       " ('inthe', 'JJ'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('important', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('financial', 'JJ'),\n",
       " ('centre', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('intellectual', 'JJ'),\n",
       " ('centre', 'NN'),\n",
       " (',', ','),\n",
       " ('too', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pos=nltk.pos_tag(word_text)\n",
    "text_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И создадим хеш-таблицу text_pos_dict для каждого значения которого будет ставится в соответствие определенная часть речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'London': 'NNP',\n",
       " 'is': 'VBZ',\n",
       " 'the': 'DT',\n",
       " 'capital': 'NN',\n",
       " 'of': 'IN',\n",
       " 'Great': 'NNP',\n",
       " 'Britain': 'NNP',\n",
       " '.': '.',\n",
       " 'It': 'PRP',\n",
       " 'one': 'CD',\n",
       " 'greatest': 'JJS',\n",
       " 'cities': 'NNS',\n",
       " 'inthe': 'JJ',\n",
       " 'world': 'NN',\n",
       " 'an': 'DT',\n",
       " 'important': 'JJ',\n",
       " 'business': 'NN',\n",
       " 'and': 'CC',\n",
       " 'financial': 'JJ',\n",
       " 'centre': 'NN',\n",
       " 'intellectual': 'JJ',\n",
       " ',': ',',\n",
       " 'too': 'RB'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pos_dict=dict(text_pos)\n",
    "text_indexing=nltk.Index((value,key) for (key,value) in text_pos_dict.items())\n",
    "text_pos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно найти слова, которые относяться к определенной части речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capital', 'world', 'business', 'centre']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_indexing[\"NN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с частотой слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd=FreqDist(word_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fd[\"cake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[\"It\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание для самостоятельной работы\n",
    "\n",
    "Задание для самостоятельной работы можете посмотреть здесь https://github.com/arinagerasimova/practice/blob/master/Задание%20для%20самостоятельной%20работы.ipynb    ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
